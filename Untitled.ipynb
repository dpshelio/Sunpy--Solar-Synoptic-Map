{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mergeSolar import *\n",
    "#from getSMImages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    solmon_pattern = (\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "        ***  DOWNLOAD SOLAR IMAGES FROM SOLARMONITOR ***\n",
    "'''\n",
    "\n",
    "__author__ = \" Gabriel García García \"\n",
    "\n",
    "__email__  = \" gabgarar@gmail.com \"\n",
    "\n",
    "\n",
    "from sunpy.util.scraper import Scraper\n",
    "from sunpy.time import TimeRange\n",
    "import urllib.request\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def getURLFromSM(inst,wv,soon,late):\n",
    "     \"\"\"\n",
    "        @ params\n",
    "            * inst : instrument \n",
    "            * wv : length wave \n",
    "            * soon  : date more recent\n",
    "            * late  : date more late\n",
    "        \n",
    "        @ return\n",
    "            * ret : list with urls from SM in that range of time\n",
    "        \n",
    "    \"\"\"\n",
    "    solmon_pattern = (\n",
    "                             'http://solarmonitor.org/data/'\n",
    "                             '%Y/%m/%d/fits/{instrument}/'\n",
    "                             '{instrument}_{wave:05d}_fd_%Y%m%d_%H%M%S.fts.gz'\n",
    "                       );\n",
    "    solmon = Scraper(solmon_pattern, instrument = inst, wave = wv);\n",
    "    \n",
    "    timerange = TimeRange(late,soon); \n",
    "    list_urls = solmon.filelist(timerange); \n",
    "    return list_urls; \n",
    "\n",
    "\n",
    "def downloadFITSfrom(urls,dir_cont):\n",
    "\n",
    "    \"\"\"\n",
    "        @ params\n",
    "            * urls : list with urls from SM\n",
    "            * dir_cont : name of the dir where we put the images\n",
    "        \n",
    "        @ return\n",
    "            * ret : all images decompressed in dir_cont\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\" The container folder is : \" + dir_cont + \"\\n\") ;\n",
    "    try:\n",
    "      os.stat(dir_cont) ; \n",
    "    except:\n",
    "      os.mkdir(dir_cont) ; \n",
    "    \n",
    "    # The first one is download the archives into dir_cont \n",
    "    \n",
    "    print(\"Downloading ...\" + \"\\n\");\n",
    "    \n",
    "    for elem in urls:\n",
    "        dir_out = elem[elem.index(dir_cont):] ; \n",
    "        \n",
    "        print(\"\\t\" + \"Path : \" + dir_out + \"\\n\"); \n",
    "            \n",
    "        archivo_tmp, header = urllib.request.urlretrieve(elem)\n",
    "        with open(dir_out, 'wb') as archivo:\n",
    "           with open(archivo_tmp, 'rb') as tmp:\n",
    "                archivo.write(tmp.read())\n",
    "      \n",
    "    # Second the archives are decompressed\n",
    "    \n",
    "    print(\"Decompressing ...\" + \"\\n\")\n",
    "    for path_fits in os.listdir(dir_cont):\n",
    "            if ( path_fits[-3:] == '.gz'):\n",
    "                path     = dir_cont + \"/\" + path_fits ; \n",
    "                print(\"\\t\" + \"The archieve will be descompressed as :\" + path[:-3] + \"\\n\"); \n",
    "                with gzip.open(path, 'rb') as f_in:\n",
    "                    with open(path[:-3], 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out);\n",
    "                        f_in.close(); \n",
    "                        f_out.close();\n",
    "                        os.remove(path); \n",
    "                        \n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = 'swap'\n",
    "wave = 174\n",
    "soon = '2015-01-01T16:00:00'\n",
    "late = '2015-01-01'\n",
    "\n",
    "urls = getURLFromSM(inst,wave,soon,late) ; \n",
    "\n",
    "for elem in urls:\n",
    "    print(elem[elem.index(inst):])\n",
    "    #print(elem[:-3])\n",
    "downloadFITSfrom(urls,inst) ; \n",
    "\n",
    "#str.replace(/abc/g, '');\n",
    "#mergeSolarImagesFromDir(\"FITS_def/\",25,\"OUT/mapa_sinaptico.png\",50,\"sdoaia171\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
